import torch
import torch.nn.functional as F
from lpips_pytorch import LPIPS

# you can install lpips_pytorch with
# !pip install git+https://github.com/logasja/lpips-pytorch.git

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


def distribution_matching_loss(mu_real, mu_fake, x, min_dm_step, max_dm_step,
                               bs, forward_diffusion, guide_w):
    # mu_real, mu_fake: denoising networks for real and fake distribution
    # x: fake sample generated by our one-step generator
    # min_dm_step, max_dm_step: timestep intervals for computing distribution matching loss
    # bs: batch size

    # random timesteps
    timestep = torch.randint(low=min_dm_step, high=max_dm_step, size=(bs,), device=device)
    # Diffuse generated sample by injecting noise
    # e.g. noise_x = x + noise * sigma_t (EDM)
    noisy_x = forward_diffusion(x, timestep)
    # denoise using real and fake denoiser
    with torch.no_grad():
        pred_fake_image = mu_fake.compute_x0(noisy_x, timestep, guide_w)
        pred_real_image = mu_real.compute_x0(noisy_x, timestep, guide_w)
    # The weighting_factor diverges slightly from our
    # paper’s equation, adapting to accomodate the mean
    # prediction scheme we use here.
    weighting_factor = torch.abs(x - pred_real_image).mean(dim=[1, 2, 3], keepdim=True)
    grad = (pred_fake_image - pred_real_image) / weighting_factor
    # the loss that would enforce above grad
    loss = F.mse_loss(x, (x - grad).detach()) * 0.5
    return loss


def denoising_loss(pred_fake_image, x):
    # pred_fake_image: denoised output by mu_fake on x_t
    # x: fake sample generated by our one-step generator
    # weight: weighting strategy(SNR+1/0.5ˆ2 for EDM, SNR for SDv1.5)
    # weight = 1  # TO DO: what is weight?
    loss = F.mse_loss(pred_fake_image, x, reduction='mean')
    return loss


criterion = LPIPS(
    net_type='alex',  # choose a network type from ['alex', 'squeeze', 'vgg']
    version='0.1'  # Currently, v0.1 is supported
).to(device)


def normalize(x):
    # x = x.clamp(-1, 1)
    return x


def lpips(x, y):
    x = torch.nn.functional.upsample_bilinear(x, size=(224, 224))
    y = torch.nn.functional.upsample_bilinear(y, size=(224, 224))
    return criterion(normalize(x), normalize(y)) / x.shape[0]
