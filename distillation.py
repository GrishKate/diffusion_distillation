import torch
import torch.nn.functional as F
import lpips
# for installation of lpips see https://github.com/richzhang/PerceptualSimilarity


def distribution_matching_loss(mu_real, mu_fake, x, min_dm_step, max_dm_step,
                               bs, forward_diffusion):
    # mu_real, mu_fake: denoising networks for real and fake distribution
    # x: fake sample generated by our one-step generator
    # min_dm_step, max_dm_step: timestep intervals for computing distribution matching loss
    # bs: batch size

    # random timesteps
    timestep = torch.randint(low=min_dm_step, high=max_dm_step, size=(bs)).to(x.device)
    # Diffuse generated sample by injecting noise
    # e.g. noise_x = x + noise * sigma_t (EDM)
    noisy_x = forward_diffusion(x, timestep)
    # denoise using real and fake denoiser
    with torch.no_grad():
        pred_fake_image = mu_fake(noisy_x, timestep)
        pred_real_image = mu_real(noisy_x, timestep)
    # The weighting_factor diverges slightly from our
    # paper’s equation, adapting to accomodate the mean
    # prediction scheme we use here.
    weighting_factor = torch.abs(x - pred_real_image).mean(dim=[1, 2, 3], keepdim=True)
    grad = (pred_fake_image - pred_real_image) / weighting_factor
    # the loss that would enforce above grad
    loss = 0.5 * F.mse_loss(x, (x - grad).detach())
    return loss


def denoising_loss(pred_fake_image, x):
    # pred_fake_image: denoised output by mu_fake on x_t
    # x: fake sample generated by our one-step generator
    # weight: weighting strategy(SNR+1/0.5ˆ2 for EDM, SNR for SDv1.5)
    weight = 1  # TO DO: what is weight?
    loss = torch.mean(weight * (pred_fake_image - x) ** 2)
    return loss


loss_fn_alex = lpips.LPIPS(net='alex')


def lpips(x, y, normalize=None):
    # image should be RGB, IMPORTANT: normalized to [-1,1]
    # TO DO : define normalize
    x = normalize(x)
    y = normalize(y)
    return loss_fn_alex(x, y)
